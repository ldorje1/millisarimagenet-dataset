{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCKuWndD8y1s",
        "outputId": "578989f0-c096-4d3a-a2b9-254b48a64ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# from torchvision.models import efficientnet_v2_l\n",
        "import os\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuv6EL93JtTV"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1BLiH6I83hr",
        "outputId": "e370d8d3-7c78-4dc6-cadc-5ff95a0dff10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "# To reproduce the result, please follow the same hyperparameters from the paper\n",
        "BATCH_SIZE = 100\n",
        "NUM_EPOCHS = 10\n",
        "NUM_CLASSES = 10\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYTRuDZmKxj9"
      },
      "source": [
        "Load the SAR image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmZcYnhj8_TA"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "\n",
        "dataset_path = \"PATH TO THE DATASET\"\n",
        "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Image distributions train/valid/test 80/10/10\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
        "\n",
        "# 80/10/10 Dataset split\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "class_names = full_dataset.classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4MVGCay5EDm"
      },
      "source": [
        "Choose the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXRkpJSPiRHq"
      },
      "outputs": [],
      "source": [
        "# MODEL SELECTION -------------------->\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "def get_model(model_name, num_classes, device, pretrained=True):\n",
        "    if model_name == \"efficientnet_v2_l\":  # 117,247,082\n",
        "        model = models.efficientnet_v2_l(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif model_name == \"convnext_base\": # 87,576,714\n",
        "        model = models.convnext_base(pretrained=pretrained)\n",
        "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
        "    elif model_name == \"vit_b_16\": # 85,806,346\n",
        "        model = models.vit_b_16(pretrained=pretrained)\n",
        "        model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
        "    elif model_name == \"swin_v2_b\": # 86,916,098\n",
        "        model = models.swin_v2_b(pretrained=pretrained)\n",
        "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "    elif model_name == \"resnet152\": # 58,164,298\n",
        "        model = models.resnet152(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "# Chose your pretrained model\n",
        "model_name = \"resnet152\"\n",
        "\n",
        "model = get_model(model_name, NUM_CLASSES, device, pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIfa_41ndjc0"
      },
      "source": [
        "Traning and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-k3-fo-BmC",
        "outputId": "bf7ba948-c681-4e0b-fa24-1c65f2de98cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Resuming from checkpoint: /content/drive/MyDrive/Colab Notebooks/ML_model_sar_synthetic_data_project/checkpoints/resnet152_checkpoint.pth\n"
          ]
        }
      ],
      "source": [
        "# TRAINING AND VALIDAITON -------------------->\n",
        "import os\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Checkpoint settings\n",
        "checkpoint_dir = \"Path to save the checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "resume = True # Set to False to start fresh\n",
        "checkpoint_path = f\"{checkpoint_dir}/{model_name}_checkpoint.pth\"\n",
        "\n",
        "# Training configuration\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Initialize variables\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "start_epoch = 0\n",
        "\n",
        "# -------- RESUME IF NEEDED -------- #\n",
        "if resume and os.path.exists(checkpoint_path):\n",
        "    print(f\"✓ Resuming from checkpoint: {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    train_losses = checkpoint['train_losses']\n",
        "    val_accuracies = checkpoint['val_accuracies']\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "else:\n",
        "    print(\"✓ Starting training from scratch\")\n",
        "\n",
        "# -------- TRAINING & VALIDATION LOOP -------- #\n",
        "for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    train_pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for images, labels in train_pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_pbar.set_postfix({\n",
        "            'loss': total_loss / (total / BATCH_SIZE),\n",
        "            'acc': correct / total * 100\n",
        "        })\n",
        "\n",
        "    train_acc = correct / total * 100\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {total_loss:.3f} | Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "    train_losses.append(total_loss / len(train_loader))\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    val_pbar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_acc = val_correct / val_total * 100\n",
        "    val_accuracies.append(val_acc)\n",
        "    print(f\"           Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # --- Save Checkpoint ---\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_losses': train_losses,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }, checkpoint_path)\n",
        "    print(f\"✓ Checkpoint saved at epoch {epoch+1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E0YKbyUM6US"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3iWez2FRLKp"
      },
      "outputs": [],
      "source": [
        "# EVALUATE THE TRAINED MODEL ON TEST BATCH -------------------->\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "model.eval()\n",
        "test_correct, test_total = 0, 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "test_pbar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\n[Final Test Accuracy] {test_acc*100:.2f}%\")\n",
        "\n",
        "print(\"\\ns Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "\n",
        "# GENERATE CONFUSION MATRIX -------------------->\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))  # adjust size as needed\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model"
      ],
      "metadata": {
        "id": "tQ-Wlkhor7BP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGKbQDm9nFr0",
        "outputId": "58abc512-8a5c-458a-ff45-13c195ab9858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model saved to: /content/drive/MyDrive/Colab Notebooks/ML_model_sar_synthetic_data_project/trained_models/resnet152_weights_20250626_001156.pth\n"
          ]
        }
      ],
      "source": [
        "# SAVE THE TRAINED MODEL -------------------->\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Set save directory (on Google Drive or local)\n",
        "save_dir = \"SAVE THE TRAINED MODEL\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Dynamic model filename using model_name and timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_filename = f\"{model_name}_weights_{timestamp}.pth\"\n",
        "\n",
        "# Full path\n",
        "model_path = os.path.join(save_dir, model_filename)\n",
        "\n",
        "# Save model weights\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"✓ Model saved to: {model_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}